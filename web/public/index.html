<script src="https://assets.crowd.aws/crowd-html-elements.js"></script>

<div id='document-text' style="display: none;">
  CROWD SOURCING IMAGE SEGMENTATION WITH iaSTAPLE Dmitrij Schlesinger?† Florian Jug?‡ Gene Myers‡ Carsten Rother† Dagmar Kainmuller ¨ ‡ † Computer Vision Lab Dresden, Dresden University of Technology ‡ Max Planck Institute of Molecular Cell Biology and Genetics ? authors contributed equally ABSTRACT We propose a novel label fusion technique as well as a crowdsourcing protocol to efficiently obtain accurate epithelial cell segmentations from non-expert crowd workers. Our label fusion technique simultaneously estimates the true segmentation, the performance levels of individual crowd workers, and an image segmentation model in the form of a pairwise Markov random field. We term our approach image-aware STAPLE (iaSTAPLE) since our image segmentation model seamlessly integrates into the well-known and widely used STAPLE approach. In an evaluation on a light microscopy dataset containing more than 5000 membrane labeled epithelial cells of a fly wing, we show that iaSTAPLE outperforms STAPLE in terms of segmentation accuracy as well as in terms of the accuracy of estimated crowd worker performance levels, and is able to correctly segment 99% of all cells when compared to expert segmentations. These results show that iaSTAPLE is a highly useful tool for crowd sourcing image segmentation. Index Terms— Epithelial cell segmentation, Crowdsourcing, Markovian Random Fields, iaSTAPLE I. INTRODUCTION Cell segmentation is an important and ubiquitous step in the process of scientific discovery in biology and in clinical applications. Ground truth (GT) segmentations of cells in microscopic images are not only needed for biomedical analyses, but also for training and evaluating automated segmentation methods and anatomy models. Due to rapidly evolving microscopes, fluorescent dyes, and markers, there is no such thing as a “default” appearance of cells in microscopic images. It is therefore common practice to manually generate GT segmentations for each new task to be solved. Since this is a tedious and time consuming task, the amount and quality of available GT is often rather low. We propose an alternative solution for GT generation: Instead of asking a few (expensive) experts to generate GT, we aim at crowd-sourcing this task to many non-expert workers. We are grateful to the Pallas Ludens GmbH and especially to D. Kondermann for providing the crowd sourcing platform. Financial support by the BMBF for the competence center for Big Data ScaDS and the 031A099 project is gratefully acknowledged. We also thank the European Research Council (ERC, grant agreement No 647769) for their support. Computations were performed at the ZIH at TU Dresden. Fig. 1. Microscopic image of a developing fly wing (crop). Our technique extends the popular STAPLE approach [1] by simultaneously estimating not only the true segmentation and user performance levels, but jointly also learning an image segmentation model in the form of a pairwise Markovian random field (MRF, cf. Section III). We call our new method “iaSTAPLE”, for image-aware STAPLE. Our method yields “more informed” estimates than STAPLE by means of the additional image model, and it enables the segmentation of image regions that were not processed by crowd workers at all. This leads to significantly improved overall performance, as we demonstrate in a quantitative evaluation. Landman et al. [2] showed that STAPLE offers a straightforward way to deal with partial as well as multiple segmentations by the same user. Their approach, termed STAPLER, thus reveals an important feature of STAPLE not shown in [1]. In the remainder of this document we will, for simplicity, use the abbreviation STAPLE to refer to both, the original STAPLE [1] and STAPLER [2]. The LOP STAPLE approach [3] employs an MRF-based segmentation model. However, as opposed to our proposed method, LOP STAPLE uses a hand-crafted, un-trained MRF model and relies on approximate mean field based inference. Non-local STAPLE [4] shares our idea of making use of image intensities. However, intensities are not exploited in the form of an appearance model for segmentation as we propose, but in a different context, namely to improve the registration of atlases. The approach closest to our own work is probably iSTAPLE [5], where image intensities are used as an appearance model for segmentation. However, iSTAPLE employs a pixel-independent segmentation model as well as a simple Gaussian probability distribution of gray-values as appearance model. Our method, in contrast, uses a learned pairwise MRF for segmentations and a Gaussian Mixture model with shading to model appearances. Our main contributions are: (i) A novel crowd-sourcing workflow for efficiently segmenting all cells in membrane labeled epithelia (cf. Section II). (ii) A generic label fusion technique that can be used in the context of many image
</div>
<div id='encodedImage' style="display: none;">
  https://arxiv.org/pdf/1702.06461.pdf
</div>
<div id="metadata" style="display: none;">
  { "foo": "bar" }
</div>

<crowd-form>
    <input name="annotations" id="annotations" type="hidden">

     <!-- Prevent crowd-form from creating its own button -->
    <crowd-button form-action="submit" style="display: none;"></crowd-button>
</crowd-form>

<!-- Custom annotation user interface is rendered here -->
<div id="root"></div>

<crowd-button id="submitButton">Submit</crowd-button>

<script>
    document.querySelector('crowd-form').onsubmit = function() {
        document.getElementById('annotations').value = JSON.stringify(JSON.parse(document.querySelector('pre').innerText));
    };

    document.getElementById('submitButton').onclick = function() {
        document.querySelector('crowd-form').submit();
    };
</script>
